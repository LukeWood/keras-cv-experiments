{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537f046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 1000\n",
    "CHECKPOINT_PATH = \"checkpoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74791332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(dataset, bounding_box_format):\n",
    "    color = tf.constant(((255.0, 0, 0),))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, example in enumerate(dataset.take(9)):\n",
    "        images, boxes = example[\"images\"], example[\"bounding_boxes\"]\n",
    "        boxes = keras_cv.bounding_box.convert_format(\n",
    "            boxes, source=bounding_box_format, target=\"rel_yxyx\", images=images\n",
    "        )\n",
    "        boxes = boxes.to_tensor(default_value=-1)\n",
    "        plotted_images = tf.image.draw_bounding_boxes(images, boxes[..., :4], color)\n",
    "        plt.subplot(9 // 3, 9 // 3, i + 1)\n",
    "        plt.imshow(plotted_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# train_ds is batched as a (images, bounding_boxes) tuple\n",
    "# bounding_boxes are ragged\n",
    "train_ds, train_dataset_info = keras_cv.datasets.pascal_voc.load(\n",
    "    bounding_box_format=\"xywh\", split=\"train\", batch_size=BATCH_SIZE\n",
    ")\n",
    "val_ds, val_dataset_info = keras_cv.datasets.pascal_voc.load(\n",
    "    bounding_box_format=\"xywh\", split=\"validation\", batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594c137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_cv.models.object_detection.retina_net.__internal__ import (\n",
    "    layers as layers_lib,\n",
    ")\n",
    "PredictionHead = layers_lib.PredictionHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf28de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 The KerasCV Authors\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class FeaturePyramid(keras.layers.Layer):\n",
    "    \"\"\"Builds the Feature Pyramid with the feature maps from the backbone.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_c3_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
    "        self.conv_c4_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
    "        self.conv_c5_1x1 = keras.layers.Conv2D(256, 1, 1, \"same\")\n",
    "        self.conv_c3_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
    "        self.conv_c4_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
    "        self.conv_c5_3x3 = keras.layers.Conv2D(256, 3, 1, \"same\")\n",
    "        self.conv_c6_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n",
    "        self.conv_c7_3x3 = keras.layers.Conv2D(256, 3, 2, \"same\")\n",
    "        self.upsample_2x = keras.layers.UpSampling2D(2)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        c3_output, c4_output, c5_output = inputs\n",
    "        p3_output = self.conv_c3_1x1(c3_output)\n",
    "        p4_output = self.conv_c4_1x1(c4_output)\n",
    "        p5_output = self.conv_c5_1x1(c5_output)\n",
    "        p4_output = p4_output + self.upsample_2x(p5_output)\n",
    "        p3_output = p3_output + self.upsample_2x(p4_output)\n",
    "        \n",
    "        p3_output = self.conv_c3_3x3(p3_output) + p3_output\n",
    "        p4_output = self.conv_c4_3x3(p4_output) + p4_output\n",
    "        p5_output = self.conv_c5_3x3(p5_output) + p5_output\n",
    "        \n",
    "        p6_output = self.conv_c6_3x3(c5_output)\n",
    "        p7_output = self.conv_c7_3x3(tf.nn.relu(p6_output))\n",
    "        return p3_output, p4_output, p5_output, p6_output, p7_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d698f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b359959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_head = PredictionHead(20*9, num_conv_layers=0, bias_initializer=prior_probability)\n",
    "box_head = PredictionHead(4*9, num_conv_layers=0, bias_initializer='zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d74881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cv.models.RetinaNet(\n",
    "    classes=20,\n",
    "    feature_pyramid = FeaturePyramid(),\n",
    "    classification_head=classification_head,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    backbone=\"resnet50\",\n",
    "    backbone_weights=\"imagenet\",\n",
    "    include_rescaling=True,\n",
    "    evaluate_train_time_metrics=False,\n",
    ")\n",
    "# Fine-tuning a RetinaNet is as simple as setting backbone.trainable = False\n",
    "model.backbone.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a9982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  1/313 [..............................] - ETA: 2:33:41 - loss: 13516.7861 - classification_loss: 13503.1758 - box_loss: 13.3824"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate=0.1, momentum=0.9, global_clipnorm=10.0)\n",
    "model.compile(\n",
    "    classification_loss=keras_cv.losses.FocalLoss(from_logits=True, reduction=\"none\"),\n",
    "    box_loss=keras_cv.losses.SmoothL1Loss(l1_cutoff=1.0, reduction=\"none\"),\n",
    "    optimizer=optimizer,\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir=\"logs\"),\n",
    "    keras.callbacks.EarlyStopping(patience=15),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=10),\n",
    "    # Uncomment to train your own RetinaNet\n",
    "    keras.callbacks.ModelCheckpoint(CHECKPOINT_PATH, save_weights_only=True),\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds.take(20),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfecdde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An important nuance to note is that by default the KerasCV RetinaNet does not evaluate\n",
    "metrics at train time.  This is to ensure optimal GPU performance and TPU compatibility.\n",
    "If you want to evaluate train time metrics, you may pass\n",
    "`evaluate_train_time_metrics=True` to the `keras_cv.models.RetinaNet` constructor.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## Evaluation with COCO Metrics\n",
    "\n",
    "KerasCV offers a suite of in-graph COCO metrics that support batch-wise evaluation.\n",
    "More information on these metrics is available in:\n",
    "\n",
    "- [Efficient Graph-Friendly COCO Metric Computation for Train-Time Model Evaluation](https://arxiv.org/abs/2207.12120)\n",
    "- [Using KerasCV COCO Metrics](https://keras.io/guides/keras_cv/coco_metrics/)\n",
    "\n",
    "Let's construct two COCO metrics, an instance of\n",
    "`keras_cv.metrics.COCOMeanAveragePrecision` with the parameterization to match the\n",
    "standard COCO Mean Average Precision metric, and `keras_cv.metrics.COCORecall`\n",
    "parameterized to match the standard COCO Recall metric.\n",
    "\"\"\"\n",
    "\n",
    "metrics = [\n",
    "    keras_cv.metrics.COCOMeanAveragePrecision(\n",
    "        class_ids=range(20),\n",
    "        bounding_box_format=\"xywh\",\n",
    "        name=\"Mean Average Precision\",\n",
    "    ),\n",
    "    keras_cv.metrics.COCORecall(\n",
    "        class_ids=range(20),\n",
    "        bounding_box_format=\"xywh\",\n",
    "        max_detections=100,\n",
    "        name=\"Recall\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Next, we can evaluate the metrics by re-compiling the model, and running\n",
    "`model.evaluate()`:\n",
    "\"\"\"\n",
    "\n",
    "model.load_weights(INFERENCE_CHECKPOINT_PATH)\n",
    "model.compile(\n",
    "    classification_loss=keras_cv.losses.FocalLoss(from_logits=True, reduction=\"none\"),\n",
    "    box_loss=keras_cv.losses.SmoothL1Loss(l1_cutoff=1.0, reduction=\"none\"),\n",
    "    optimizer=tf.optimizers.SGD(learning_rate=0.1, momentum=0.9, global_clipnorm=10.0),\n",
    "    metrics=metrics,\n",
    ")\n",
    "metrics = model.evaluate(val_ds.take(20), return_dict=True)\n",
    "print(metrics)\n",
    "# {\"Mean Average Precision\": 0.612, \"Recall\": 0.767}\n",
    "\n",
    "\"\"\"\n",
    "## Inference\n",
    "\n",
    "KerasCV makes object detection inference simple.  `model.predict(images)` returns a\n",
    "RaggedTensor of bounding boxes.  By default, `RetinaNet.predict()` will perform\n",
    "a non max suppression operation for you.\n",
    "\"\"\"\n",
    "\n",
    "model = keras_cv.models.RetinaNet(\n",
    "    classes=20,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    backbone=\"resnet50\",\n",
    "    backbone_weights=\"imagenet\",\n",
    "    include_rescaling=True,\n",
    ")\n",
    "model.load_weights(INFERENCE_CHECKPOINT_PATH)\n",
    "\n",
    "\n",
    "def visualize_detections(model):\n",
    "    train_ds, val_dataset_info = keras_cv.datasets.pascal_voc.load(\n",
    "        bounding_box_format=\"xywh\", split=\"train\", batch_size=9\n",
    "    )\n",
    "    train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    images, labels = next(iter(train_ds.take(1)))\n",
    "    predictions = model.predict(images)\n",
    "    color = tf.constant(((255.0, 0, 0),))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    predictions = keras_cv.bounding_box.convert_format(\n",
    "        predictions, source=\"xywh\", target=\"rel_yxyx\", images=images\n",
    "    )\n",
    "    predictions = predictions.to_tensor(default_value=-1)\n",
    "    plotted_images = tf.image.draw_bounding_boxes(images, predictions[..., :4], color)\n",
    "    for i in range(9):\n",
    "        plt.subplot(9 // 3, 9 // 3, i + 1)\n",
    "        plt.imshow(plotted_images[i].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_detections(model)\n",
    "\n",
    "\"\"\"\n",
    "To get good results, you should train for at least 100 epochs.  You also need to\n",
    "tune the prediction decoder layer.  This can be done by passing a custom prediction\n",
    "decoder to the RetinaNet constructor as follows:\n",
    "\"\"\"\n",
    "\n",
    "prediction_decoder = keras_cv.layers.NmsPredictionDecoder(\n",
    "    bounding_box_format=\"xywh\",\n",
    "    anchor_generator=keras_cv.models.RetinaNet.default_anchor_generator(\n",
    "        bounding_box_format=\"xywh\"\n",
    "    ),\n",
    "    suppression_layer=keras_cv.layers.NonMaxSuppression(\n",
    "        iou_threshold=0.75,\n",
    "        bounding_box_format=\"xywh\",\n",
    "        classes=20,\n",
    "        confidence_threshold=0.85,\n",
    "    ),\n",
    ")\n",
    "model = keras_cv.models.RetinaNet(\n",
    "    classes=20,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    backbone=\"resnet50\",\n",
    "    backbone_weights=None,\n",
    "    include_rescaling=True,\n",
    "    prediction_decoder=prediction_decoder,\n",
    ")\n",
    "model.load_weights(INFERENCE_CHECKPOINT_PATH)\n",
    "visualize_detections(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
